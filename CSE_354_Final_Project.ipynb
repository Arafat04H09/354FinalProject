{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC9eVwO6t0VI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "!pip install transformers torch\n",
        "from transformers import pipeline\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "!pip install scikit-learn\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv', nrows=25)\n",
        "print(f\"Number of training examples: {len(train_df)}\")\n",
        "print(train_df.head())"
      ],
      "metadata": {
        "id": "6GaVMPBfujeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    \n",
        "    # Tokenize the text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    \n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    \n",
        "    # Join the filtered tokens back into a string\n",
        "    processed_text = ' '.join(filtered_tokens)\n",
        "    \n",
        "    return processed_text\n",
        "\n",
        "# Apply the preprocessing function \n",
        "train_df['clean_text'] = train_df['DOCUMENT'].apply(preprocess_text)\n",
        "print(train_df.head())"
      ],
      "metadata": {
        "id": "JHTBn432u0-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Example text and labels for classification\n",
        "text = train_df[\"DOCUMENT\"][0]\n",
        "labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Perform zero-shot classification\n",
        "result = classifier(text, labels)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnAag4y0vFEb",
        "outputId": "3d202607-d754-4e4e-c6a8-c117437ee37b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': \"Germany's Landesbank Baden Wuertemberg won EU approval Tuesday for a state bailout after it promised to shrink its balance sheet by 40 percent and refocus on lending to companies.\\n The bank was several state-owned German institutions to run into trouble last year after it ran up more huge losses from investing in high-risk proprietary trading and capital market activities -- a business the EU has now told it to shun.\\n Seven current and former managers of the bank are also being investigated by German authorities for risking or damaging the bank's capital by carrying out or failing to block investments in high-risk deals worth hundreds of millions from 2006.\\n The European Commission said its Tuesday approval for the state rescue of the bank and its new restructuring plan would allow it become a viable business again -- and that the cutbacks would help limit the unfair advantage over rivals that the bank would get from the state aid.\\n Stuttgart-based LBBW earlier this year received a capital injection of (EURO)5 billion from the bank's shareholders  all of them public authorities or state-owned  including the state of Baden-Wuerttemberg  the region's savings bank association and the city of Stuttgart.\", 'labels': ['negative', 'positive', 'neutral'], 'scores': [0.4819658696651459, 0.3674817383289337, 0.1505524069070816]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"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\"\n",
        "\n",
        "# Function to call the Hugging Face Inference API for zero-shot classification\n",
        "def classify_text(text, labels, max_retries=3, sleep_duration=1):\n",
        "    url = \"https://api-inference.huggingface.co/models/facebook/bart-large-mnli\"\n",
        "    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "    data = {\n",
        "        \"inputs\": text,\n",
        "        \"parameters\": {\"candidate_labels\": labels},\n",
        "        \"options\": {\"use_cache\": False}\n",
        "    }\n",
        "\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        elif response.status_code == 429:\n",
        "            print(f\"Rate limit reached. Retrying in {sleep_duration} seconds...\")\n",
        "            time.sleep(sleep_duration)\n",
        "            retries += 1\n",
        "        else:\n",
        "            print(f\"Error {response.status_code}: {response.text}\")\n",
        "            return None\n",
        "\n",
        "    print(f\"Max retries reached. Skipping this request.\")\n",
        "    return None\n",
        "\n",
        "def classify_text_iterative(text, labels, iterations=3):\n",
        "    for i in range(iterations):\n",
        "        result = classify_text(text, labels)\n",
        "        if result is not None:\n",
        "            return result\n",
        "    return None\n",
        "\n",
        "def classify_text_chain_of_thought(text, labels, iterations=3):\n",
        "    for i in range(iterations):\n",
        "        result = classify_text(text, labels)\n",
        "        if result is not None:\n",
        "            max_score_label = get_sentiment_label(extract_sentiment_scores(result))\n",
        "            if max_score_label in labels:\n",
        "                labels.remove(max_score_label)\n",
        "            else:\n",
        "                return result\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "t_CnydVIvW_c"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the candidate labels for classification\n",
        "labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Define a list to store the classification results for each row\n",
        "classifications = []\n",
        "\n",
        "def extract_sentiment_scores(result):\n",
        "    if result is None or 'choices' not in result:\n",
        "        return None\n",
        "    choices = result['choices']\n",
        "    scores = {choice['label']: choice['score'] for choice in choices}\n",
        "    return scores\n",
        "\n",
        "def get_sentiment_label(sentiment_scores):\n",
        "    if sentiment_scores is None:\n",
        "        return None\n",
        "    max_score_label = max(sentiment_scores, key=sentiment_scores.get)\n",
        "    return max_score_label\n",
        "\n",
        "def evaluate_methods(ground_truth, zero_shot_labels, iterative_labels, chain_of_thought_labels):\n",
        "    metrics = {\n",
        "        'zero_shot': {\n",
        "            'accuracy': accuracy_score(ground_truth, zero_shot_labels),\n",
        "            'f1_score': f1_score(ground_truth, zero_shot_labels, average='weighted')\n",
        "        },\n",
        "        'iterative': {\n",
        "            'accuracy': accuracy_score(ground_truth, iterative_labels),\n",
        "            'f1_score': f1_score(ground_truth, iterative_labels, average='weighted')\n",
        "        },\n",
        "        'chain_of_thought': {\n",
        "            'accuracy': accuracy_score(ground_truth, chain_of_thought_labels),\n",
        "            'f1_score': f1_score(ground_truth, chain_of_thought_labels, average='weighted')\n",
        "        }\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "\n",
        "maxIterations = 25\n",
        "iterations = 0\n",
        "# Loop through each row in the dataframe\n",
        "for index, row in train_df.iterrows():\n",
        "\n",
        "    if iterations >= maxIterations:\n",
        "      break\n",
        "    # Classify the text in the current row using zero-shot classification\n",
        "    text = row['clean_text']\n",
        "    trueSentiment = row['TRUE_SENTIMENT']\n",
        "    result = classify_text(text, labels)\n",
        "    if result is None:\n",
        "        print(f\"Error classifying text in row {index}: result is None\")\n",
        "        continue\n",
        "    \n",
        "    # Extract the sentiment scores from the result and add them to the classifications list\n",
        "    scores = extract_sentiment_scores(result)\n",
        "    classifications.append(scores)\n",
        "    \n",
        "    iterations += 1\n",
        "    for i in range(len(result['scores'])):\n",
        "      if result['scores'][0] > result['scores'][1] and result['scores'][0] > result['scores'][2]:\n",
        "        print(trueSentiment, labels[0])\n",
        "      elif result['scores'][1] > result['scores'][0] and result['scores'][1] > result['scores'][2]:\n",
        "        print(trueSentiment, labels[1])\n",
        "      elif result['scores'][2] > result['scores'][1] and result['scores'][2] > result['scores'][0]:\n",
        "        print(trueSentiment, labels[2])\n",
        "\n",
        "    \n",
        "# Initialize a list of None values with the same length as the DataFrame\n",
        "sentiment_scores = [None] * len(train_df)\n",
        "\n",
        "# Replace the first 25 values with the calculated sentiment scores\n",
        "sentiment_scores[:maxIterations] = classifications\n",
        "\n",
        "# Add the new column to the DataFrame\n",
        "train_df['sentiment_scores'] = sentiment_scores\n",
        "\n",
        "# Print the first few rows of the DataFrame to confirm the sentiment scores were calculated\n",
        "print(train_df.head())\n",
        "\n",
        "# Perform analysis on the first 25 rows\n",
        "analyzed_df = train_df.head(maxIterations)\n"
      ],
      "metadata": {
        "id": "jrEgO22Hvi7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list to store the classification results for each row for the iterative method\n",
        "classifications_iterative = []\n",
        "\n",
        "# Define a list to store the classification results for each row for the chain-of-thought reasoning method\n",
        "classifications_chain_of_thought = []\n",
        "\n",
        "maxIterations = 25\n",
        "iterations = 0\n",
        "\n",
        "# Loop through each row in the dataframe\n",
        "for index, row in train_df.iterrows():\n",
        "\n",
        "    if iterations >= maxIterations:\n",
        "        break\n",
        "\n",
        "    # Classify the text in the current row using the iterative method\n",
        "    text = row['clean_text']\n",
        "    result_iterative = classify_text_iterative(text, labels, iterations=3)\n",
        "    if result_iterative is None:\n",
        "        print(f\"Error classifying text in row {index} (iterative method): result is None\")\n",
        "        continue\n",
        "\n",
        "    # Extract the sentiment scores from the result and add them to the classifications_iterative list\n",
        "    scores_iterative = extract_sentiment_scores(result_iterative)\n",
        "    classifications_iterative.append(scores_iterative)\n",
        "\n",
        "    # Classify the text in the current row using the chain-of-thought reasoning method\n",
        "    result_chain_of_thought = classify_text_chain_of_thought(text, labels, iterations=3)\n",
        "    if result_chain_of_thought is None:\n",
        "        print(f\"Error classifying text in row {index} (chain-of-thought reasoning method): result is None\")\n",
        "        continue\n",
        "\n",
        "    # Extract the sentiment scores from the result and add them to the classifications_chain_of_thought list\n",
        "    scores_chain_of_thought = extract_sentiment_scores(result_chain_of_thought)\n",
        "    classifications_chain_of_thought.append(scores_chain_of_thought)\n",
        "\n",
        "    iterations += 1\n",
        "    print(\"ITERATIVE RESULTS FOR INDEX\", index)\n",
        "    for i in range(len(result_iterative['scores'])):\n",
        "      if result_iterative['scores'][0] > result_iterative['scores'][1] and result_iterative['scores'][0] > result_iterative['scores'][2]:\n",
        "        print(row['TRUE_SENTIMENT'], labels[0])\n",
        "      elif result_iterative['scores'][1] > result_iterative['scores'][0] and result_iterative['scores'][1] > result_iterative['scores'][2]:\n",
        "        print(row['TRUE_SENTIMENT'], labels[1])\n",
        "      elif result_iterative['scores'][2] > result_iterative['scores'][1] and result_iterative['scores'][2] > result_iterative['scores'][0]:\n",
        "        print(row['TRUE_SENTIMENT'], labels[2])\n",
        "\n",
        "    print('------------------')\n",
        "    print(\"CHAIN OF THOUGHT RESULTS FOR INDEX\", index)\n",
        "    for i in range(len(result_chain_of_thought['scores'])):\n",
        "      if result_chain_of_thought['scores'][0] > result_chain_of_thought['scores'][1] and result_chain_of_thought['scores'][0] > result_chain_of_thought['scores'][2]:\n",
        "        print(row['TRUE_SENTIMENT'], labels[0])\n",
        "      elif result_chain_of_thought['scores'][1] > result_chain_of_thought['scores'][0] and result_chain_of_thought['scores'][1] > result_chain_of_thought['scores'][2]:\n",
        "        print(row['TRUE_SENTIMENT'], labels[1])\n",
        "      elif result_chain_of_thought['scores'][2] > result_chain_of_thought['scores'][1] and result_chain_of_thought['scores'][2] > result_chain_of_thought['scores'][0]:\n",
        "        print(row['TRUE_SENTIMENT'], labels[2])\n",
        "\n",
        "\n",
        "processed_rows = iterations\n",
        "\n",
        "# Add new columns to the dataframe to store the classification results\n",
        "train_df.loc[:processed_rows - 1, 'sentiment_scores_iterative'] = classifications_iterative\n",
        "train_df.loc[:processed_rows - 1, 'sentiment_scores_chain_of_thought'] = classifications_chain_of_thought\n",
        "\n",
        "# Print the first few rows of the dataframe to confirm the sentiment scores were calculated\n",
        "print(train_df.head())\n",
        "\n",
        "# Calculate sentiment labels for each method\n",
        "train_df.loc[:processed_rows - 1, 'sentiment_zero_shot'] = train_df.loc[:processed_rows - 1, 'sentiment_scores'].apply(get_sentiment_label)\n",
        "train_df.loc[:processed_rows - 1, 'sentiment_iterative'] = train_df.loc[:processed_rows - 1, 'sentiment_scores_iterative'].apply(get_sentiment_label)\n",
        "train_df.loc[:processed_rows - 1, 'sentiment_chain_of_thought'] = train_df.loc[:processed_rows - 1, 'sentiment_scores_chain_of_thought'].apply(get_sentiment_label)\n",
        "\n",
        "# Check for any 'None' or missing values\n",
        "print(train_df['TRUE_SENTIMENT'].value_counts(dropna=False))\n",
        "print(train_df['sentiment_zero_shot'].value_counts(dropna=False))\n",
        "print(train_df['sentiment_iterative'].value_counts(dropna=False))\n",
        "print(train_df['sentiment_chain_of_thought'].value_counts(dropna=False))\n",
        "\n",
        "# Evaluate the three methods\n",
        "ground_truth = train_df.loc[:processed_rows - 1, 'TRUE_SENTIMENT']\n",
        "zero_shot_labels = train_df.loc[:processed_rows - 1, 'sentiment_zero_shot']\n",
        "iterative_labels = train_df.loc[:processed_rows - 1, 'sentiment_iterative']\n",
        "chain_of_thought_labels = train_df.loc[:processed_rows - 1, 'sentiment_chain_of_thought']\n",
        "\n",
        "# Convert the ground truth labels and the predicted labels to strings\n",
        "ground_truth = ground_truth.astype(str)\n",
        "zero_shot_labels = zero_shot_labels.astype(str)\n",
        "iterative_labels = iterative_labels.astype(str)\n",
        "chain_of_thought_labels = chain_of_thought_labels.astype(str)\n",
        "\n",
        "# Call the evaluate_methods function\n",
        "metrics = evaluate_methods(ground_truth, zero_shot_labels, iterative_labels, chain_of_thought_labels)\n",
        "print(metrics)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2fRTYOuW5ZGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe with instances where at least one of the methods failed\n",
        "failed_instances = train_df[(train_df['TRUE_SENTIMENT'] != train_df['sentiment_zero_shot']) |\n",
        "                            (train_df['TRUE_SENTIMENT'] != train_df['sentiment_iterative']) |\n",
        "                            (train_df['TRUE_SENTIMENT'] != train_df['sentiment_chain_of_thought'])]\n",
        "\n",
        "# Print the failed instances\n",
        "print(failed_instances[['DOCUMENT', 'TRUE_SENTIMENT', 'sentiment_zero_shot', 'sentiment_iterative', 'sentiment_chain_of_thought']])\n",
        "\n",
        "# Check what the failed instances have in common and create hypotheses.\n"
      ],
      "metadata": {
        "id": "t81D0C6H7UaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Hypothesis\n",
        "text = \"Boy I sure do hate it when my girlfriend brings me food that I totally do not want!\"\n",
        "labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Perform zero-shot classification\n",
        "result = classifier(text, labels)\n",
        "result2 = classify_text_chain_of_thought(text, labels, iterations=3)\n",
        "result3 = classify_text_iterative(text, labels, iterations=3)\n",
        "print(result, result2, result3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baGLt1q5XzmC",
        "outputId": "f1635fee-3013-49dd-cb51-495fbd52f7b6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'Boy I sure do hate it when my girlfriend brings me food that I totally do not want!', 'labels': ['negative', 'neutral', 'positive'], 'scores': [0.981526255607605, 0.013403677381575108, 0.005070046987384558]} {'sequence': 'Boy I sure do hate it when my girlfriend brings me food that I totally do not want!', 'labels': ['negative', 'neutral', 'positive'], 'scores': [0.9815261363983154, 0.013403763063251972, 0.005070049315690994]} {'sequence': 'Boy I sure do hate it when my girlfriend brings me food that I totally do not want!', 'labels': ['negative', 'neutral', 'positive'], 'scores': [0.9815261363983154, 0.013403763063251972, 0.005070049315690994]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Hypothesis\n",
        "text = \"Wow, I hate this present! I totally didn't want something so thoughtful and perfect for me.\"\n",
        "labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Perform zero-shot classification\n",
        "result = classifier(text, labels)\n",
        "result2 = classify_text_chain_of_thought(text, labels, iterations=3)\n",
        "result3 = classify_text_iterative(text, labels, iterations=3)\n",
        "print(result, result2, result3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCd80E3zZjHP",
        "outputId": "b809feee-8cd0-4385-87de-7c37119762c2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': \"Wow, I hate this present! I totally didn't want something so thoughtful and perfect for me.\", 'labels': ['negative', 'neutral', 'positive'], 'scores': [0.9915387630462646, 0.004644458182156086, 0.0038167773745954037]} {'sequence': \"Wow, I hate this present! I totally didn't want something so thoughtful and perfect for me.\", 'labels': ['negative', 'neutral', 'positive'], 'scores': [0.9915388226509094, 0.004644447937607765, 0.0038167848251760006]} {'sequence': \"Wow, I hate this present! I totally didn't want something so thoughtful and perfect for me.\", 'labels': ['negative', 'neutral', 'positive'], 'scores': [0.9915388226509094, 0.004644447937607765, 0.0038167848251760006]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Hypothesis\n",
        "text = \"This food is too amazing. I hate it!\"\n",
        "labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Perform zero-shot classification\n",
        "result = classifier(text, labels)\n",
        "result2 = classify_text_chain_of_thought(text, labels, iterations=3)\n",
        "result3 = classify_text_iterative(text, labels, iterations=3)\n",
        "print(result, result2, result3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67AXwr_wZvBy",
        "outputId": "4ac2eaa1-3638-410c-ba79-476d9411bd43"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'This food is too amazing. I hate it!', 'labels': ['positive', 'negative', 'neutral'], 'scores': [0.5818073749542236, 0.33616647124290466, 0.0820261538028717]} {'sequence': 'This food is too amazing. I hate it!', 'labels': ['positive', 'negative', 'neutral'], 'scores': [0.5818071365356445, 0.3361665904521942, 0.08202622085809708]} {'sequence': 'This food is too amazing. I hate it!', 'labels': ['positive', 'negative', 'neutral'], 'scores': [0.5818071365356445, 0.3361665904521942, 0.08202622085809708]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Hypothesis\n",
        "text = \"I hate it. This food is too amazing!\"\n",
        "labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Perform zero-shot classification\n",
        "result = classifier(text, labels)\n",
        "result2 = classify_text_chain_of_thought(text, labels, iterations=3)\n",
        "result3 = classify_text_iterative(text, labels, iterations=3)\n",
        "print(result, result2, result3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwzYiGvoZ7sR",
        "outputId": "0095eb42-4765-468f-ca3a-709a43306bca"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'I hate it. This food is too amazing!', 'labels': ['negative', 'positive', 'neutral'], 'scores': [0.9027256369590759, 0.06868816167116165, 0.02858615666627884]} {'sequence': 'I hate it. This food is too amazing!', 'labels': ['negative', 'positive', 'neutral'], 'scores': [0.9027257561683655, 0.06868814677000046, 0.028586147353053093]} {'sequence': 'I hate it. This food is too amazing!', 'labels': ['negative', 'positive', 'neutral'], 'scores': [0.9027257561683655, 0.06868814677000046, 0.028586147353053093]}\n"
          ]
        }
      ]
    }
  ]
}